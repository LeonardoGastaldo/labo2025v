{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonardoGastaldo/labo2025v/blob/main/src/ensembles/470_GBDT_LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Ensembles de Arboles de Decision"
      ],
      "metadata": {
        "id": "O94qX1svwzoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.06 GBDT LightGBM"
      ],
      "metadata": {
        "id": "HsJFTcBZw1bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La técnica de Gradient Boosting fue creada por Jerome H. Friedman en 1999 - 2001\n",
        "<br>Se implementaron librerías ineficientes\n",
        "<br>En 2016 se crea XGBoost, en 2017 LightGBM\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nsgvDbemw9Tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paper original de  Gradient Boosting\n",
        "\n",
        "\n",
        "Friedman JH. Greedy function approximation: A gradient\n",
        "boosting machine. Ann Stat. 2001;29(5):1189–232. https://\n",
        "doi.org/10.1214/aos/1013203451.\n",
        "<br>\n",
        "https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.pdf"
      ],
      "metadata": {
        "id": "1o-6jjy0Yedk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paper XGBoost\n",
        "\n",
        "Chen, T.; Guestrin, C. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd ACM Sigkdd International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, 13–17 August 2016; pp. 785–794.\n",
        "\n",
        "https://dl.acm.org/doi/pdf/10.1145/2939672.2939785"
      ],
      "metadata": {
        "id": "14MlfCxMZWIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paper  LightGBM\n",
        "\n",
        "Ke G., Meng Q., Finley T., Wang T., Chen W., Ma W., et al.\n",
        "Lightgbm: A highly efficient gradient boosting decision tree\n",
        "Advances in Neural Information Processing Systems, 30 (2017)\n",
        "\n",
        "https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf"
      ],
      "metadata": {
        "id": "IDk5edloZpBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Videos \"simplificados\" :\n",
        "*  https://www.youtube.com/watch?v=3CC4N4z3GJc\n",
        "*  https://www.youtube.com/watch?v=2xudPOBz-vs\n",
        "*  https://www.youtube.com/watch?v=jxuNLH5dXCs\n",
        "*  https://www.youtube.com/watch?v=StWY5QWMXCw"
      ],
      "metadata": {
        "id": "ZMyXpQyJaCsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Artículos ligeros:\n",
        "*  https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/\n",
        "*   https://www.machinelearningplus.com/machine-learning/an-introduction-to-gradient-boosting-decision-trees/\n",
        "*   https://medium.com/@ruchi.awasthi63/gradient-boosted-decision-tree-clearly-explained-bd1d8c7d9923\n",
        "*   https://medium.com/data-science/a-visual-understanding-of-decision-trees-and-gradient-boosting-c6bc53f982ce\n",
        "*   https://medium.com/analytics-vidhya/introduction-to-the-gradient-boosting-algorithm-c25c653f826b\n",
        "*   https://medium.com/@datasciencewizards/understanding-the-gradient-boosting-algorithm-9fe698a352ad"
      ],
      "metadata": {
        "id": "Eyffb3AAahth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Gradient Boosting of Decision Trees es un ensemble de árboles de decisión, para un nuevo registro la predicción se hace sumando el score que cada arbol asigna a ese registro.\n",
        "\n",
        "En GBDT la construccion de los árboles es secuencial, ya que el arbol n-simo se genera para predecir el error del modelo conformado por los n-1 arboles previos, aunque sea un arbol de clasificación lo que se predice es un numero real mediante un arbol de regresión."
      ],
      "metadata": {
        "id": "0YOyfUaESdsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>Qué tipo de perturbaciones se realiza LightGBM\n",
        "\n",
        "*   Se perturba el dataset, seleccionando para cada arbol un subconjunto de las columnas.\n",
        "*   El algortimo de arbol de decisión no presenta perturbaciones"
      ],
      "metadata": {
        "id": "nF6XblBIYnY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada arbolito de LightGBM se entrena sobre un dataset perturbado, que en principio posee :\n",
        "* todos los registros del dataset original\n",
        "* solo un porcentaje *feature_fraction* de las columnas originales del dataset"
      ],
      "metadata": {
        "id": "j75A--Tsx2df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.06.1  Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "PX0qg_c0yqob"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70cdc72b-d712-4ea5-e649-1d9b7b42164f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/.drive\n"
          ]
        }
      ],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bca8b1c-5109-44eb-8095-66484c521590"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.07  LightGBM, una corrida"
      ],
      "metadata": {
        "id": "oSKhZRToy2F7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "Tjda_YGOXaPw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a23612c4-5ed1-4cda-9ff2-01c4d34df733"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Tue Nov 04 11:23:15 PM 2025'"
            ],
            "text/markdown": "'Tue Nov 04 11:23:15 PM 2025'",
            "text/latex": "'Tue Nov 04 11:23:15 PM 2025'",
            "text/plain": [
              "[1] \"Tue Nov 04 11:23:15 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1iE0U4_WCPRT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "531c2466-d6a0-4fc6-cd1a-b729aa50ca13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td>1846525</td><td>98.7</td><td>  7501208</td><td> 400.7</td><td> 13568828</td><td> 724.7</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>3580701</td><td>27.4</td><td>164841172</td><td>1257.7</td><td>171625894</td><td>1309.5</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells | 1846525 | 98.7 |   7501208 |  400.7 |  13568828 |  724.7 |\n| Vcells | 3580701 | 27.4 | 164841172 | 1257.7 | 171625894 | 1309.5 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells & 1846525 & 98.7 &   7501208 &  400.7 &  13568828 &  724.7\\\\\n\tVcells & 3580701 & 27.4 & 164841172 & 1257.7 & 171625894 & 1309.5\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb)   max used  (Mb)  \n",
              "Ncells 1846525 98.7   7501208   400.7  13568828  724.7\n",
              "Vcells 3580701 27.4 164841172  1257.7 171625894 1309.5"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BJDwdD0dCPRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba4f40b-0460-4bc1-8833-c8895d74e1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: data.table\n",
            "\n",
            "Loading required package: rpart\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘lightgbm’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe cargar SU semilla primigenia"
      ],
      "metadata": {
        "id": "M8-Pyp6CCPRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 4074\n",
        "PARAM$semilla_primigenia <- 101581\n",
        "\n",
        "# estos hiperparametros de LightGBM surgieron de una Bayesian Optimization\n",
        "PARAM$lgb$num_iterations <- 880  # cantidad de arbolitos\n",
        "PARAM$lgb$learning_rate <- 0.010770\n",
        "PARAM$lgb$feature_fraction <- 0.472695\n",
        "PARAM$lgb$min_data_in_leaf <- 729\n",
        "PARAM$lgb$num_leaves <- 301\n",
        "#PARAM$lgb$max_depth <- -1\n",
        "#PARAM$lgb$lambda_l1 <- 0.0\n",
        "#PARAM$lgb$lambda_l2 <- 0.0\n",
        "#PARAM$lgb$min_gain_to_split <- 0\n",
        "#PARAM$lgb$bagging_fraction <- 1\n",
        "#PARAM$lgb$min_sum_hessian_in_leaf <- 0.001\n",
        "#PARAM$lgb$scale_pos_weight <- 1\n",
        "#PARAM$lgb$boost_from_average <- TRUE\n",
        "#PARAM$lgb$objective <- \"binary\"\n",
        "#PARAM$lgb$first_metric_only <- FALSE\n",
        "#PARAM$lgb$drop_rate <- 0.1\n",
        "#PARAM$lgb$skip_drop <- 0.5\n",
        "#PARAM$lgb$is_unbalance <- FALSE\n",
        "#PARAM$lgb$max_drop <- 50\n",
        "#PARAM$lgb$boosting <- \"gbdt\"\n",
        "PARAM$lgb$max_bin <- 31\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ],
      "metadata": {
        "id": "peRH7ySLCPRV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"KA\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "1gZD6ZMvCPRV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\", stringsAsFactors= TRUE)"
      ],
      "metadata": {
        "id": "Xi0emX2ECPRV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paso la clase a binaria\n",
        "\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\"), 1L, 0L)]"
      ],
      "metadata": {
        "id": "-3XuBeDy1Ugj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(colnames(dataset), c(\"clase_ternaria\", \"clase01\"))"
      ],
      "metadata": {
        "id": "h8Anoo4Sel8S"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# establezco donde entreno\n",
        "\n",
        "dataset[, train := 0L]\n",
        "dataset[foto_mes %in% c(202107), train := 1L]"
      ],
      "metadata": {
        "id": "RA3cSJ6KaGwA"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[train == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset[train == 1L, clase01]\n",
        ")"
      ],
      "metadata": {
        "id": "T6Zr06HB1kMU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero el modelo\n",
        "# estos hiperparametros  salieron de una laaarga Optmizacion Bayesiana\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\") # Establezco la semilla aleatoria\n",
        "\n",
        "modelo <- lgb.train(\n",
        "  data= dtrain,\n",
        "  param= list(\n",
        "    num_iterations = PARAM$lgb$num_iterations,  # cantidad de arbolitos\n",
        "    learning_rate = PARAM$lgb$learning_rate,\n",
        "    feature_fraction = PARAM$lgb$feature_fraction,\n",
        "    feature_fraction = PARAM$lgb$min_data_in_leaf,\n",
        "    num_leaves = PARAM$lgb$num_leaves,\n",
        "    #max_depth = PARAM$lgb$max_depth,\n",
        "    #lambda_l1 = PARAM$lgb$lambda_l1,\n",
        "    #lambda_l2 = PARAM$lgb$lambda_l2,\n",
        "    #min_gain_to_split = PARAM$lgb$min_gain_to_split,\n",
        "    #bagging_fraction = PARAM$lgb$bagging_fraction,\n",
        "    #min_sum_hessian_in_leaf = PARAM$lgb$min_sum_hessian_in_leaf,\n",
        "    #scale_pos_weight = PARAM$lgb$scale_pos_weight,\n",
        "    #boost_from_average = PARAM$lgb$boost_from_average,\n",
        "    #objective = PARAM$lgb$objective,\n",
        "    #first_metric_only = PARAM$lgb$first_metric_only,\n",
        "    #drop_rate = PARAM$lgb$drop_rate,\n",
        "    #skip_drop = PARAM$lgb$skip_drop,\n",
        "    #is_unbalance = PARAM$lgb$is_unbalance,\n",
        "    #max_drop = PARAM$lgb$max_drop,\n",
        "    #boosting = PARAM$lgb$boosting,\n",
        "    max_bin = PARAM$lgb$max_bin,\n",
        "    undersampling = PARAM$trainingstrategy$undersampling,\n",
        "\n",
        "    seed= PARAM$semilla_primigenia\n",
        "  )\n",
        ")\n"
      ],
      "metadata": {
        "id": "TI9_5pii2zCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca74f7b-6c25-4651-aba2-4a438e8059ce"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: undersampling\n",
            "[LightGBM] [Warning] Unknown parameter: undersampling\n",
            "[LightGBM] [Warning] Unknown parameter: undersampling\n",
            "[LightGBM] [Warning] feature_fraction is set=0.472695, feature_fraction=729 will be ignored. Current value: feature_fraction=0.472695\n",
            "[LightGBM] [Warning] Unknown parameter: undersampling\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3612\n",
            "[LightGBM] [Info] Number of data points in the train set: 164596, number of used features: 153\n",
            "[LightGBM] [Info] Start training from score 0.007582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "69QcMsSkg9d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(modelo, \"modelo.txt\" )"
      ],
      "metadata": {
        "id": "lauiNeQDg-XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")\n"
      ],
      "metadata": {
        "id": "VQhEcNmBhF7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "Z5LYpStThlIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subidas a Kaggle\n",
        "# ordeno por probabilidad descendente\n",
        "\n",
        "setorder(tb_prediccion, -prob)"
      ],
      "metadata": {
        "id": "vSopCODCh6kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero la prediccion y subo a Kaggle\n",
        "\n",
        "tb_prediccion[, Predicted := 0L]\n",
        "tb_prediccion[prob>(1/40), Predicted := 1L]\n",
        "\n",
        "archivo_kaggle <- paste0(\"KA\", PARAM$experimento, \".csv\")\n",
        "\n",
        "# grabo el archivo\n",
        "fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "  file= archivo_kaggle,\n",
        "  sep= \",\"\n",
        ")\n",
        "\n",
        "# subida a Kaggle\n",
        "comando <- \"kaggle competitions submit\"\n",
        "competencia <- \"-c labo-i-2025-virtual-analista-sr\"\n",
        "arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "mensaje <- paste0(\"-m 'num_iterations=\", PARAM$lgb$num_iterations,\n",
        "  \"  learning_rate=\", PARAM$lgb$learning_rate,\n",
        "  \"  feature_fraction=\", PARAM$lgb$feature_fraction,\n",
        "  \"  min_data_in_leaf=\", PARAM$lgb$min_data_in_leaf,\n",
        "  \"  num_leaves=\",PARAM$lgb$num_leaves,\n",
        "  \"  max_bin=\", PARAM$lgb$max_bin,\n",
        "\"'\" )\n",
        "\n",
        "linea <- paste( comando, competencia, arch, mensaje)\n",
        "salida <- system(linea, intern=TRUE)\n",
        "cat(salida)"
      ],
      "metadata": {
        "id": "pmxc2Z0fpJAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "PK3QGWJsXk_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMr6Z1enOyd3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.08  LightGBM  optimizacion de hiperparámetros"
      ],
      "metadata": {
        "id": "lO4QwOEU-xPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La optimizacion de los hiperparámetros de LightGBM mediante el método de optimizacion bayesiana será su *caballito de batalla* durante la asignatura !"
      ],
      "metadata": {
        "id": "75FU3LjSF2uN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJBO5Dcb_B7s"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "2CeMTfCuX3bH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9708e23e-9585-4122-b6a2-22cf433f3d35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Tue Nov 04 01:32:35 PM 2025'"
            ],
            "text/markdown": "'Tue Nov 04 01:32:35 PM 2025'",
            "text/latex": "'Tue Nov 04 01:32:35 PM 2025'",
            "text/plain": [
              "[1] \"Tue Nov 04 01:32:35 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HPKFI6yP_B7s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "f3862cab-0498-4d65-da5e-424145320db2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td>1762926</td><td>94.2</td><td>3342670</td><td>178.6</td><td>2484272</td><td>132.7</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>3197423</td><td>24.4</td><td>8388608</td><td> 64.0</td><td>7914183</td><td> 60.4</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells | 1762926 | 94.2 | 3342670 | 178.6 | 2484272 | 132.7 |\n| Vcells | 3197423 | 24.4 | 8388608 |  64.0 | 7914183 |  60.4 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells & 1762926 & 94.2 & 3342670 & 178.6 & 2484272 & 132.7\\\\\n\tVcells & 3197423 & 24.4 & 8388608 &  64.0 & 7914183 &  60.4\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb)  max used (Mb) \n",
              "Ncells 1762926 94.2 3342670    178.6 2484272  132.7\n",
              "Vcells 3197423 24.4 8388608     64.0 7914183   60.4"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B6X8U6XF_B7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365310eb-5ee1-4ab9-e261-344a90a05b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: parallel\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘primes’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘DiceKriging’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘mlrMBO’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘fastmatch’, ‘RcppArmadillo’, ‘mlr’, ‘ParamHelpers’, ‘smoof’, ‘BBmisc’, ‘checkmate’, ‘lhs’, ‘parallelMap’\n",
            "\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Loading required package: mlr\n",
            "\n",
            "Loading required package: ParamHelpers\n",
            "\n",
            "Loading required package: smoof\n",
            "\n",
            "Loading required package: checkmate\n",
            "\n",
            "\n",
            "Attaching package: ‘checkmate’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:DiceKriging’:\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe cargar SU semilla primigenia"
      ],
      "metadata": {
        "id": "_qZHeAHdCJQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 40802\n",
        "PARAM$semilla_primigenia <- 248887\n",
        "\n",
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "PARAM$trainingstrategy$undersampling <- 1.0\n",
        "\n",
        "PARAM$hyperparametertuning$iteraciones <- 30 # iteracines bayesianas\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM\n",
        "PARAM$lgbm$param_fijos <- list(\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= TRUE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  verbosity= -100,\n",
        "  force_row_wise= TRUE, # para evitar warning\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "  max_bin= 31,\n",
        "  num_iterations= 2048,  # valor grande, lo limita early_stopping_rounds\n",
        "  early_stopping_rounds= 200\n",
        ")\n",
        "\n",
        "# Aqui se cargan los bordes de los hiperparametros\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  makeNumericParam(\"learning_rate\", lower= 0.01, upper= 0.3),\n",
        "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
        "  makeIntegerParam(\"num_leaves\", lower= 8L, upper= 2048L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L)\n",
        ")"
      ],
      "metadata": {
        "id": "2y3Ai8F6CJQ2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC de cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"))\n",
        "\n",
        "  # uno la lista de hiperparametros : fijos + variables\n",
        "  param_completo <- c(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo,\n",
        "    verbose= -100\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # esta es la forma de devolver un parametro extra\n",
        "  attr(AUC, \"extras\") <- list(\"num_iterations\"= modelocv$best_iter)\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message( \"AUC: \", AUC)\n",
        "  return(AUC)\n",
        "}"
      ],
      "metadata": {
        "id": "NnPKiCHuCwVo"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui se inicia el programa"
      ],
      "metadata": {
        "id": "P7Pw1KLeE3UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "w1lb19whCJQ3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "\n",
        "kbayesiana <- \"bayesiana.RDATA\""
      ],
      "metadata": {
        "id": "QvOokHUvuolF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "xcOJpoFvCJQ3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "JorOk_A8EhSy"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "\n",
        "dataset[\n",
        "  foto_mes %in% c(202107),\n",
        "  clase01 := ifelse(clase_ternaria == \"BAJA+2\", 1L, 0L)\n",
        "]"
      ],
      "metadata": {
        "id": "JDg9xZVYrwvj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "E68xpDYAr0nK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind= \"L'Ecuyer-CMRG\")\n",
        "dataset[, azar := runif(nrow(dataset))]\n",
        "dataset[, training := 0L]\n",
        "\n",
        "dataset[\n",
        "  foto_mes %in% c(202107) &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ],
      "metadata": {
        "id": "G8zeYUfSr3GF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ],
      "metadata": {
        "id": "se8_aKuMr5CV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ce67f62d-0209-4a72-b729-27ee12ed9e15"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "164596"
            ],
            "text/markdown": "164596",
            "text/latex": "164596",
            "text/plain": [
              "[1] 164596"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "154"
            ],
            "text/markdown": "154",
            "text/latex": "154",
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "CsRYGGeN-1ID"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ],
      "metadata": {
        "id": "TissqCCHD1uZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb5c381-803a-45b8-c239-8d211813016a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "Tue Nov 04 06:40:19 PM 2025\n",
            "\n",
            "AUC: 0.903339756391488\n",
            "\n",
            "Tue Nov 04 06:41:34 PM 2025\n",
            "\n",
            "AUC: 0.899174001734773\n",
            "\n",
            "Tue Nov 04 06:43:02 PM 2025\n",
            "\n",
            "AUC: 0.904211272386097\n",
            "\n",
            "Tue Nov 04 06:45:30 PM 2025\n",
            "\n",
            "AUC: 0.902598239505554\n",
            "\n",
            "Tue Nov 04 06:47:38 PM 2025\n",
            "\n",
            "AUC: 0.898742772211766\n",
            "\n",
            "Tue Nov 04 06:49:06 PM 2025\n",
            "\n",
            "AUC: 0.904467627004107\n",
            "\n",
            "Tue Nov 04 06:53:39 PM 2025\n",
            "\n",
            "AUC: 0.90064952740983\n",
            "\n",
            "Tue Nov 04 06:54:58 PM 2025\n",
            "\n",
            "AUC: 0.902681649984225\n",
            "\n",
            "Tue Nov 04 06:56:00 PM 2025\n",
            "\n",
            "AUC: 0.893033572072436\n",
            "\n",
            "Tue Nov 04 06:57:07 PM 2025\n",
            "\n",
            "AUC: 0.904234479605971\n",
            "\n",
            "Tue Nov 04 06:58:47 PM 2025\n",
            "\n",
            "AUC: 0.887150174867716\n",
            "\n",
            "Tue Nov 04 07:01:36 PM 2025\n",
            "\n",
            "AUC: 0.904100487407411\n",
            "\n",
            "Tue Nov 04 07:03:34 PM 2025\n",
            "\n",
            "AUC: 0.89652151366398\n",
            "\n",
            "Tue Nov 04 07:04:58 PM 2025\n",
            "\n",
            "AUC: 0.903128455178404\n",
            "\n",
            "Tue Nov 04 07:06:37 PM 2025\n",
            "\n",
            "AUC: 0.903458388029611\n",
            "\n",
            "Tue Nov 04 07:08:55 PM 2025\n",
            "\n",
            "AUC: 0.902213704597003\n",
            "\n",
            "[mbo] 0: learning_rate=0.148; feature_fraction=0.808; num_leaves=816; min_data_in_leaf=5182 : y = 0.903 : 75.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.171; feature_fraction=0.719; num_leaves=267; min_data_in_leaf=1927 : y = 0.899 : 87.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0509; feature_fraction=0.414; num_leaves=459; min_data_in_leaf=3715 : y = 0.904 : 148.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.124; feature_fraction=0.491; num_leaves=1517; min_data_in_leaf=2903 : y = 0.903 : 127.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.281; feature_fraction=0.586; num_leaves=1235; min_data_in_leaf=4253 : y = 0.899 : 87.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0189; feature_fraction=0.161; num_leaves=1094; min_data_in_leaf=6125 : y = 0.904 : 273.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.182; feature_fraction=0.753; num_leaves=213; min_data_in_leaf=3070 : y = 0.901 : 78.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.194; feature_fraction=0.929; num_leaves=1791; min_data_in_leaf=7792 : y = 0.903 : 62.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.223; feature_fraction=0.107; num_leaves=572; min_data_in_leaf=1277 : y = 0.893 : 66.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0904; feature_fraction=0.271; num_leaves=1819; min_data_in_leaf=4932 : y = 0.904 : 99.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.234; feature_fraction=0.53; num_leaves=1966; min_data_in_leaf=471 : y = 0.887 : 169.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0356; feature_fraction=0.876; num_leaves=702; min_data_in_leaf=6816 : y = 0.904 : 117.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.284; feature_fraction=0.964; num_leaves=952; min_data_in_leaf=2181 : y = 0.897 : 84.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.106; feature_fraction=0.259; num_leaves=43; min_data_in_leaf=5786 : y = 0.903 : 98.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0736; feature_fraction=0.607; num_leaves=1364; min_data_in_leaf=930 : y = 0.903 : 138.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.254; feature_fraction=0.357; num_leaves=1590; min_data_in_leaf=7336 : y = 0.902 : 99.4 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 07:10:35 PM 2025\n",
            "\n",
            "AUC: 0.902162462908249\n",
            "\n",
            "[mbo] 1: learning_rate=0.0278; feature_fraction=0.996; num_leaves=1362; min_data_in_leaf=2337 : y = 0.902 : 137.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 07:12:53 PM 2025\n",
            "\n",
            "AUC: 0.904105030736132\n",
            "\n",
            "[mbo] 2: learning_rate=0.0859; feature_fraction=0.503; num_leaves=1315; min_data_in_leaf=7995 : y = 0.904 : 140.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 07:15:14 PM 2025\n",
            "\n",
            "AUC: 0.90307642590061\n",
            "\n",
            "[mbo] 3: learning_rate=0.0706; feature_fraction=0.375; num_leaves=1148; min_data_in_leaf=4852 : y = 0.903 : 115.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 07:17:10 PM 2025\n",
            "\n",
            "AUC: 0.90364067496543\n",
            "\n",
            "[mbo] 4: learning_rate=0.0332; feature_fraction=0.101; num_leaves=2048; min_data_in_leaf=7307 : y = 0.904 : 170.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 07:20:01 PM 2025\n",
            "\n",
            "AUC: 0.903062742568659\n",
            "\n",
            "[mbo] 5: learning_rate=0.282; feature_fraction=0.962; num_leaves=8; min_data_in_leaf=7998 : y = 0.903 : 51.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 6 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 07:20:53 PM 2025\n",
            "\n",
            "AUC: 0.906005115834055\n",
            "\n",
            "[mbo] 6: learning_rate=0.01; feature_fraction=0.269; num_leaves=8; min_data_in_leaf=8000 : y = 0.906 : 576.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 07:30:29 PM 2025\n",
            "\n",
            "AUC: 0.907146980390325\n",
            "\n",
            "[mbo] 7: learning_rate=0.0101; feature_fraction=0.1; num_leaves=10; min_data_in_leaf=55 : y = 0.907 : 457.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 8 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 07:38:07 PM 2025\n",
            "\n",
            "AUC: 0.906085441576846\n",
            "\n",
            "[mbo] 8: learning_rate=0.01; feature_fraction=0.54; num_leaves=10; min_data_in_leaf=17 : y = 0.906 : 702.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 9 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 07:49:50 PM 2025\n",
            "\n",
            "AUC: 0.906092452684104\n",
            "\n",
            "[mbo] 9: learning_rate=0.0101; feature_fraction=0.101; num_leaves=10; min_data_in_leaf=3309 : y = 0.906 : 444.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 07:57:15 PM 2025\n",
            "\n",
            "AUC: 0.90122442308732\n",
            "\n",
            "[mbo] 10: learning_rate=0.0378; feature_fraction=0.101; num_leaves=10; min_data_in_leaf=2 : y = 0.901 : 210.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 11 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 08:00:46 PM 2025\n",
            "\n",
            "AUC: 0.897836948225175\n",
            "\n",
            "[mbo] 11: learning_rate=0.01; feature_fraction=0.108; num_leaves=1732; min_data_in_leaf=11 : y = 0.898 : 1068.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 12 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 08:18:34 PM 2025\n",
            "\n",
            "AUC: 0.904528550264605\n",
            "\n",
            "[mbo] 12: learning_rate=0.01; feature_fraction=0.102; num_leaves=329; min_data_in_leaf=894 : y = 0.905 : 325.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:24:00 PM 2025\n",
            "\n",
            "AUC: 0.904313605917196\n",
            "\n",
            "[mbo] 13: learning_rate=0.112; feature_fraction=0.999; num_leaves=2048; min_data_in_leaf=7983 : y = 0.904 : 73.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:25:14 PM 2025\n",
            "\n",
            "AUC: 0.904090048753723\n",
            "\n",
            "[mbo] 14: learning_rate=0.0892; feature_fraction=0.999; num_leaves=10; min_data_in_leaf=2981 : y = 0.904 : 67.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:26:22 PM 2025\n",
            "\n",
            "AUC: 0.903414208282664\n",
            "\n",
            "[mbo] 15: learning_rate=0.01; feature_fraction=0.746; num_leaves=9; min_data_in_leaf=5785 : y = 0.903 : 243.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 16 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 08:30:25 PM 2025\n",
            "\n",
            "AUC: 0.904047274788302\n",
            "\n",
            "[mbo] 16: learning_rate=0.0284; feature_fraction=0.1; num_leaves=117; min_data_in_leaf=8000 : y = 0.904 : 184.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:33:30 PM 2025\n",
            "\n",
            "AUC: 0.90114268913215\n",
            "\n",
            "[mbo] 17: learning_rate=0.264; feature_fraction=0.302; num_leaves=10; min_data_in_leaf=7999 : y = 0.901 : 89.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:35:00 PM 2025\n",
            "\n",
            "AUC: 0.899871379823147\n",
            "\n",
            "[mbo] 18: learning_rate=0.164; feature_fraction=0.1; num_leaves=24; min_data_in_leaf=8000 : y = 0.9 : 85.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:36:27 PM 2025\n",
            "\n",
            "AUC: 0.903964949274345\n",
            "\n",
            "[mbo] 19: learning_rate=0.0531; feature_fraction=1; num_leaves=2045; min_data_in_leaf=7999 : y = 0.904 : 83.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:37:50 PM 2025\n",
            "\n",
            "AUC: 0.905581801062523\n",
            "\n",
            "[mbo] 20: learning_rate=0.0101; feature_fraction=0.434; num_leaves=926; min_data_in_leaf=7997 : y = 0.906 : 490.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 21 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 08:46:01 PM 2025\n",
            "\n",
            "AUC: 0.90316745994658\n",
            "\n",
            "[mbo] 21: learning_rate=0.0862; feature_fraction=0.999; num_leaves=2048; min_data_in_leaf=2871 : y = 0.903 : 91.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:47:33 PM 2025\n",
            "\n",
            "AUC: 0.900340229860605\n",
            "\n",
            "[mbo] 22: learning_rate=0.3; feature_fraction=0.19; num_leaves=2047; min_data_in_leaf=7992 : y = 0.9 : 75.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:48:49 PM 2025\n",
            "\n",
            "AUC: 0.903858723172551\n",
            "\n",
            "[mbo] 23: learning_rate=0.149; feature_fraction=0.998; num_leaves=2040; min_data_in_leaf=8000 : y = 0.904 : 63.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 08:49:53 PM 2025\n",
            "\n",
            "AUC: 0.905483366268736\n",
            "\n",
            "[mbo] 24: learning_rate=0.01; feature_fraction=0.102; num_leaves=509; min_data_in_leaf=7971 : y = 0.905 : 492.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 25 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 08:58:06 PM 2025\n",
            "\n",
            "AUC: 0.890091332127154\n",
            "\n",
            "[mbo] 25: learning_rate=0.101; feature_fraction=0.997; num_leaves=61; min_data_in_leaf=1 : y = 0.89 : 121.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 09:00:09 PM 2025\n",
            "\n",
            "AUC: 0.904096639004832\n",
            "\n",
            "[mbo] 26: learning_rate=0.0869; feature_fraction=0.999; num_leaves=427; min_data_in_leaf=6039 : y = 0.904 : 83.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 09:01:32 PM 2025\n",
            "\n",
            "AUC: 0.90568521707917\n",
            "\n",
            "[mbo] 27: learning_rate=0.0632; feature_fraction=0.92; num_leaves=9; min_data_in_leaf=2807 : y = 0.906 : 74.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 09:02:47 PM 2025\n",
            "\n",
            "AUC: 0.901564509305673\n",
            "\n",
            "[mbo] 28: learning_rate=0.128; feature_fraction=0.129; num_leaves=1970; min_data_in_leaf=6477 : y = 0.902 : 89.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 09:04:17 PM 2025\n",
            "\n",
            "AUC: 0.901183665513214\n",
            "\n",
            "[mbo] 29: learning_rate=0.0814; feature_fraction=0.103; num_leaves=1308; min_data_in_leaf=2686 : y = 0.901 : 80.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 09:05:39 PM 2025\n",
            "\n",
            "AUC: 0.904380157648215\n",
            "\n",
            "[mbo] 30: learning_rate=0.0102; feature_fraction=0.999; num_leaves=10; min_data_in_leaf=2938 : y = 0.904 : 239.4 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter:= .I]\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y, -num_iterations)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  list(learning_rate, feature_fraction, num_leaves, min_data_in_leaf, num_iterations)\n",
        "]\n",
        "\n",
        "print(PARAM$out$lgbm$mejores_hiperparametros)"
      ],
      "metadata": {
        "id": "aC-ls8JfNDTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f18f10-6c88-4592-b3db-a181a0775f3b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   learning_rate feature_fraction num_leaves min_data_in_leaf num_iterations\n",
            "           <num>            <num>      <int>            <int>          <int>\n",
            "1:    0.01010166        0.1002503         10               55           1840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "5dPpsZpcX6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cabf617b-2c4a-4c08-ce81-93b6919c79b4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Tue Nov 04 09:09:39 PM 2025'"
            ],
            "text/markdown": "'Tue Nov 04 09:09:39 PM 2025'",
            "text/latex": "'Tue Nov 04 09:09:39 PM 2025'",
            "text/plain": [
              "[1] \"Tue Nov 04 09:09:39 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vu-1vf5LrVg"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}